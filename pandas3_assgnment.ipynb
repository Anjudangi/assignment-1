{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521787cb-c9dc-486a-a3f5-2bba37434c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2440338-4903-41c3-b317-e70428bb8482",
   "metadata": {},
   "source": [
    "Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "course_name = [‘Data Science’, ‘Machine Learning’, ‘Big Data’, ‘Data Engineer’]\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {‘course_name’ : course_name, ‘duration’ : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a10854-7589-448a-aff0-eeed1fc12ebf",
   "metadata": {},
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed28ad66-3a9d-4927-b243-76dd66661a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans.1\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration': duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40516ae-a0ee-469d-a59a-c8145294f2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f126b2-4835-4613-a866-67a3e7e4c0fa",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660b4d21-0b8b-4a18-a1e6-4682fa0eac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.2\n",
    "#In pandas, both the loc and iloc functions are used to select data from a DataFrame, but they differ in how they perform the selection and the types of arguments they accept:\n",
    "\n",
    "#loc (label-based selection):\n",
    "\n",
    "#loc is primarily used for label-based indexing. This means that you use row and column labels to select data from the DataFrame\n",
    "\n",
    "#df.loc['row_label', 'column_label']  # Select a single element\n",
    "\n",
    "#iloc (integer-based selection):\n",
    "#iloc is used for integer-based indexing. It allows you to select data based on integer positions (i.e., row and column indices) rather than labels.\n",
    "#df.iloc[0, 1]  # Select a single element at the first row and second column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e528c-ec00-432c-b542-ffc6ee4ec0c1",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "Did you observe any difference in both the outputs? If so then explain it.\n",
    "Consider the below code to answer further questions:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b5243e3-5488-451a-bd88-163460c507a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of new_df.loc[2]:\n",
      " column_1    0.870613\n",
      "column_2    0.043951\n",
      "column_3    0.517810\n",
      "column_4    0.369049\n",
      "column_5    0.129663\n",
      "column_6    0.528298\n",
      "Name: 2, dtype: float64\n",
      "Output of new_df.iloc[2]:\n",
      " column_1    0.923256\n",
      "column_2    0.124605\n",
      "column_3    0.447043\n",
      "column_4    0.122977\n",
      "column_5    0.166688\n",
      "column_6    0.802449\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ans.3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Reindex the DataFrame\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df1.reindex(reindex)\n",
    "\n",
    "# Output of new_df.loc[2] and new_df.iloc[2]\n",
    "output_loc = new_df.loc[2]\n",
    "output_iloc = new_df.iloc[2]\n",
    "\n",
    "print(\"Output of new_df.loc[2]:\\n\", output_loc)\n",
    "print(\"Output of new_df.iloc[2]:\\n\", output_iloc)\n",
    "#The new_df DataFrame has been reindexed according to the reindex variable, so the row labels have changed. The original DataFrame df1 had row labels [1, 2, 3, 4, 5, 6], and after reindexing, the row labels of new_df are [1, 2, 3, 4], corresponding to the new order specified in reindex.\n",
    "\n",
    "#Here's the difference between new_df.loc[2] and new_df.iloc[2]:\n",
    "\n",
    "#new_df.loc[2]: This uses label-based indexing. It will select the row labeled '2'. In the reindexed new_df, the label '2' corresponds to the third row of the original DataFrame df1, which was at position 2 before reindexing.\n",
    "\n",
    "#new_df.iloc[2]: This uses integer-based indexing. It will select the row at position 2, which corresponds to the original third row of df1.\n",
    "\n",
    "#So, there is a difference in the output because loc and iloc operate based on different indexing methods. loc considers the label '2' (third row after reindexing), while iloc considers the integer position 2 (original third row before reindexing).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Is this conversation helpful so far?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c05d4-aefa-4bcc-8400-466607ffa988",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a31fe657-fa29-48af-847c-b9e8cd4ebf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i) Mean of each column:\n",
      " column_1    0.502797\n",
      "column_2    0.354259\n",
      "column_3    0.614876\n",
      "column_4    0.448482\n",
      "column_5    0.686266\n",
      "column_6    0.666635\n",
      "dtype: float64\n",
      "(ii) Standard deviation of 'column_2': 0.2898160680473169\n"
     ]
    }
   ],
   "source": [
    "# ans.4\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Mean of each column\n",
    "column_means = df1.mean()\n",
    "\n",
    "# (ii) Standard deviation of 'column_2'\n",
    "column_2_std = df1['column_2'].std()\n",
    "\n",
    "print(\"(i) Mean of each column:\\n\", column_means)\n",
    "print(\"(ii) Standard deviation of 'column_2':\", column_2_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640567ab-092e-4e72-9ce9-15b3d6e42acd",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bf7b2c-9ccb-499d-80d9-5cc6805b4a0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mString Data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Attempt to calculate the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# ans.5\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = \"String Data\"\n",
    "\n",
    "# Attempt to calculate the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "\n",
    "print(\"Mean of 'column_2':\", mean_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df42ea7-9736-421a-9998-bcb0cccf176a",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4a223e6-99eb-493f-a61d-51a66a59bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.6\n",
    "#In pandas, window functions (also known as rolling or rolling window functions) are a powerful feature that allows you to perform operations on a rolling or moving window of data in a DataFrame or Series. These functions are particularly useful for time series data and other ordered data where you want to analyze data over a specified window or interval.\n",
    "#Window functions in pandas operate on a set of consecutive data points within a specified window, and they can perform various calculations and aggregations. Some common types of window functions in pandas include:\n",
    "\n",
    "#rolling(): This function creates a rolling view of the data. It is often used in conjunction with aggregation functions like mean, sum, min, max, and std to calculate statistics over a rolling window. You can specify the size of the rolling window using the window parameter.\n",
    "# Example: Calculate the rolling mean over a window of size 3\n",
    "#df['column'].rolling(window=3).mean()\n",
    "#expanding(): The expanding window function calculates aggregations for all data points from the start to the current position. It is often used for cumulative statistics.\n",
    "# Example: Calculate the cumulative sum using an expanding window\n",
    "#df['column'].expanding().sum()\n",
    "#ewm(): Exponentially weighted moving average (EWMA) is a type of window function that gives more weight to recent data points. It's useful for smoothing and trend analysis. You can specify the span, center of mass, or half-life to control the weight decay.\n",
    "# Example: Calculate the EWMA with a specified span\n",
    "#df['column'].ewm(span=10).mean()\n",
    "#rolling().apply(): You can apply custom functions to the rolling window using the apply() method. This allows you to perform user-defined calculations on the data within the window.\n",
    "# Example: Apply a custom function to the rolling window\n",
    "#df['column'].rolling(window=3).apply(lambda x: custom_function(x))\n",
    "#These window functions are incredibly useful for time series analysis, data smoothing, and feature engineering. They enable you to compute statistics over dynamic subsets of your data, providing valuable insights into patterns and trends within your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372cdae-e5ae-4baa-87fc-8ca51110db6c",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d80fda2d-2cfa-43f0-8815-61a5af9bf1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: October\n",
      "Current Year: 2023\n"
     ]
    }
   ],
   "source": [
    "# ans.7\n",
    "from datetime import datetime\n",
    "# Get the current date and time\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Extract and print the current month and year\n",
    "current_month = current_date.strftime(\"%B\")  # Full month name\n",
    "current_year = current_date.year\n",
    "\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c951c7-1429-4829-a6b6-8a97e3644f71",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ec7c80e-49fc-4bcb-9843-33235f7950eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2004-12-08\n",
      "Enter the second date (YYYY-MM-DD):  2004-11-23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Difference: -15 days, 0 hours, 0 minutes\n"
     ]
    }
   ],
   "source": [
    "#ans.8\n",
    "date_str1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date_str2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Convert input strings to datetime objects\n",
    "date1 = pd.to_datetime(date_str1)\n",
    "date2 = pd.to_datetime(date_str2)\n",
    "\n",
    "# Calculate the time difference\n",
    "time_diff = date2 - date1\n",
    "\n",
    "# Extract days, hours, and minutes from the time difference\n",
    "days = time_diff.days\n",
    "hours, remainder = divmod(time_diff.seconds, 3600)\n",
    "minutes = remainder // 60\n",
    "\n",
    "# Display the result\n",
    "print(f\"Time Difference: {days} days, {hours} hours, {minutes} minutes\")\n",
    "#This program prompts the user to enter two dates in the format \"YYYY-MM-DD\", converts them to Pandas datetime objects, calculates the time difference using timedelta, and then extracts and displays the difference in days, hours, and minutes.\n",
    "\n",
    "#Here's how the program works:\n",
    "\n",
    "#The user is prompted to enter the first and second dates.\n",
    "#The input strings are converted to Pandas datetime objects using pd.to_datetime().\n",
    "#The time difference between the two dates is calculated using the - operator, resulting in a timedelta.\n",
    "#The days, hours, and minutes are extracted from the timedelta, and the result is displayed.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4c48e-54b4-4f84-9c4c-33aa14b53075",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc37589-90d9-4c54-8834-770d49d1fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.9\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Prompt the user for the column name to convert to categorical\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "\n",
    "# Prompt the user for category order (comma-separated)\n",
    "categories_str = input(\"Enter the category order (comma-separated): \")\n",
    "\n",
    "# Convert the comma-separated categories to a list\n",
    "category_order = [category.strip() for category in categories_str.split(',')]\n",
    "# Convert the specified column to categorical data type\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame based on the categorical column\n",
    "sorted_df = df.sort_values(by=column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(\"Sorted Data:\")\n",
    "print(sorted_df)\n",
    "#Here's how the program works:\n",
    "#The user is prompted to enter the file path for the CSV file containing categorical data.\n",
    "#The program reads the CSV file into a Pandas DataFrame.\n",
    "#The user is prompted to enter the column name in the DataFrame that they want to convert to a categorical data type.\n",
    "#The user is prompted to enter the category order as a comma-separated list.\n",
    "#The program converts the specified column to a categorical data type with the specified category order.\n",
    "#The DataFrame is sorted based on the categorical column.\n",
    "#The sorted data is displayed.\n",
    "#Make sure the CSV file is in the correct format with the specified column and category order for this program to work effectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b229cbe2-5864-4258-87f1-d189120e303f",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45e971-2f67-44ef-8235-7500da5c4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.10\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user for the CSV file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming you have a 'Date' column and columns for each product category (e.g., 'Category1', 'Category2')\n",
    "# You can customize this based on your CSV file structure\n",
    "\n",
    "# Create a stacked bar chart\n",
    "df.set_index('Date').plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Customize the chart labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Stacked Bar Chart of Product Category Sales Over Time')\n",
    "\n",
    "# Display the chart\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "plt.show()\n",
    "#Here's how the program works:\n",
    "#The user is prompted to enter the file path for the CSV file containing sales data.\n",
    "#The program reads the CSV file into a Pandas DataFrame.\n",
    "#It assumes that you have a 'Date' column and separate columns for each product category. You should adapt this code according to the actual structure of your CSV file.\n",
    "#It creates a stacked bar chart using the plot() function with kind='bar' and stacked=True to stack the categories.\n",
    "#The chart's labels and title are customized.\n",
    "#Finally, it displays the chart using Matplotlib.\n",
    "#This program allows you to visualize the sales of different product categories over time using a stacked bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5220ce-be7e-4a6a-8ce8-af9dae894a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
